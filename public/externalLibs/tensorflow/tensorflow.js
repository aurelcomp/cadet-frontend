async function getData() {
  const houseDataReq = await fetch('https://raw.githubusercontent.com/meetnandu05/ml1/master/house.json');  
  const houseData = await houseDataReq.json();  
  const cleaned = houseData.map(house => ({
    price: house.Price,
    rooms: house.AvgAreaNumberofRooms,
  }))
  .filter(house => (house.price != null && house.rooms != null));
  
  return cleaned;
}



 async function run() {
 // Load and plot the original input data that we are going to train on.
 const data = await getData();
 const values = data.map(d => ({
   x: d.rooms,
   y: d.price,
 }));

 tfvis.render.scatterplot(
   {name: 'No.of rooms v Price'},
   {values}, 
   {
     xLabel: 'No. of rooms',
     yLabel: 'Price',
     height: 300
   }
 );

    // More code will be added below

    // Create the model
    const model = createModel();  
    tfvis.show.modelSummary({name: 'Model Summary'}, model);


    // Convert the data to a form we can use for training.
    const tensorData = convertToTensor21(data);
    const {inputs, labels} = tensorData;
 
    // Train the model  
    await trainModel2(model, inputs, labels);
    console.log('Done Training');

    testModel2(model, data, tensorData);
    // Plot in the tab
    // not really working, to improve
    const div = document.getElementsByClassName('side-content-text');
    const visor = document.getElementsByClassName('css-nil visor-surfaces');
    console.log(visor)
    console.log(visor[0])
    div[1].appendChild(visor[0]);
    
   

  }

  function createModel() {
    // Create a sequential model
    const model = tf.sequential(); 
    
    // Add a single hidden layer
    model.add(tf.layers.dense({inputShape: [1], units: 1, useBias: true}));
    
    // Add an output layer
    model.add(tf.layers.dense({units: 1, useBias: true}));
  
    return model;
  }

  function convertToTensor21(data) {
  
    return tf.tidy(() => {
      // Step 1. Shuffle the data    
      tf.util.shuffle(data);
      // Step 2. Convert data to Tensor
      const inputs = data.map(d => d.rooms)
      const labels = data.map(d => d.price);
      const inputTensor = tf.tensor2d(inputs, [inputs.length, 1]);
      const labelTensor = tf.tensor2d(labels, [labels.length, 1]);
      //Step 3. Normalize the data to the range 0 - 1 using min-max scaling
      const inputMax = inputTensor.max();
      const inputMin = inputTensor.min();  
      const labelMax = labelTensor.max();
      const labelMin = labelTensor.min();
      const normalizedInputs = inputTensor.sub(inputMin).div(inputMax.sub(inputMin));
      const normalizedLabels = labelTensor.sub(labelMin).div(labelMax.sub(labelMin));
      return {
        inputs: normalizedInputs,
        labels: normalizedLabels,
        // Return the min/max bounds so we can use them later.
        inputMax,
        inputMin,
        labelMax,
        labelMin,
      }
    });  
  }

  async function trainModel2(model, inputs, labels) {
    // Prepare the model for training.  
    model.compile({
      optimizer: tf.train.adam(),
      loss: tf.losses.meanSquaredError,
      metrics: ['mse'],
    });
    
    const batchSize = 28;
    const epochs = 20;
    
    return await model.fit(inputs, labels, {
      batchSize,
      epochs,
      shuffle: true,
      callbacks: tfvis.show.fitCallbacks(
        { name: 'Training Performance' },
        ['loss', 'mse'], 
        { height: 200, callbacks: ['onEpochEnd'] }
      )
    });
  }

  function testModel2(model, inputData, normalizationData) {
    const {inputMax, inputMin, labelMin, labelMax} = normalizationData;  
    
    // Generate predictions for a uniform range of numbers between 0 and 1;
    // We un-normalize the data by doing the inverse of the min-max scaling 
    // that we did earlier.
    const [xs, preds] = tf.tidy(() => {
      
      const xs = tf.linspace(0, 1, 100);      
      const preds = model.predict(xs.reshape([100, 1]));      
      
      const unNormXs = xs
        .mul(inputMax.sub(inputMin))
        .add(inputMin);
      
      const unNormPreds = preds
        .mul(labelMax.sub(labelMin))
        .add(labelMin);
      
      // Un-normalize the data
      return [unNormXs.dataSync(), unNormPreds.dataSync()];
    });
    
   
    const predictedPoints = Array.from(xs).map((val, i) => {
      return {x: val, y: preds[i]}
    });
    
    const originalPoints = inputData.map(d => ({
      x: d.rooms, y: d.price,
    }));
    
    
    tfvis.render.scatterplot(
      {name: 'Model Predictions vs Original Data'}, 
      {values: [originalPoints, predictedPoints], series: ['original', 'predicted']}, 
      {
        xLabel: 'No. of rooms',
        yLabel: 'Price',
        height: 300
      }
    );

  }

// // ---------------------------------------------
// // TensorFlow - Do It yourself 
// // ---------------------------------------------



const dataEmbedding = [ [ -0.17391221225261688,
  0.1458580642938614,
  0.011645497754216194,
  -0.036689672619104385,
  -0.016892869025468826,
  -0.04397802799940109,
  -0.0893208235502243,
  -0.11309146881103516,
  0.15732496976852417,
  -0.040737420320510864,
  0.2436342090368271,
  -0.01710376888513565,
  -0.232982337474823,
  -0.04124161973595619,
  -0.0714859664440155,
  0.020590543746948242,
  -0.17314980924129486,
  -0.14564605057239532,
  0.06396036595106125,
  -0.06357991695404053,
  0.08741102367639542,
  0.001416428480297327,
  -0.028150172904133797,
  0.07451038807630539,
  -0.17602092027664185,
  -0.32520267367362976,
  -0.07329503446817398,
  -0.08634811639785767,
  -0.01298999972641468,
  -0.09351596236228943,
  0.09097083657979965,
  0.08064725995063782,
  -0.14841777086257935,
  0.02583955228328705,
  0.005829105153679848,
  0.07302279025316238,
  -0.014010009355843067,
  0.027488797903060913,
  0.22214823961257935,
  0.029841363430023193,
  -0.11249472945928574,
  -0.0373292900621891,
  -0.004483089316636324,
  0.3924064040184021,
  0.11870411038398743,
  -0.012208404019474983,
  0.018893036991357803,
  -0.0486157163977623,
  0.09421011805534363,
  -0.21070030331611633,
  0.06981869786977768,
  0.23953565955162048,
  0.11426125466823578,
  0.02772582694888115,
  0.06210529804229736,
  -0.10229828208684921,
  -0.02434355765581131,
  0.11284387111663818,
  -0.20927806198596954,
  0.15116730332374573,
  0.08003555238246918,
  -0.08449136465787888,
  -0.025511927902698517,
  -0.08372879028320312,
  0.15792475640773773,
  0.0652313157916069,
  -0.13694855570793152,
  -0.1424623280763626,
  0.11563105881214142,
  -0.12711617350578308,
  -0.06751565635204315,
  0.13662239909172058,
  -0.0799219012260437,
  -0.2838304042816162,
  -0.21500472724437714,
  0.10512537509202957,
  0.3695484697818756,
  0.19140735268592834,
  -0.14881929755210876,
  0.06785967946052551,
  -0.09010699391365051,
  -0.09908461570739746,
  0.05445901304483414,
  0.00987876858562231,
  -0.0774201899766922,
  0.01492762379348278,
  -0.135817289352417,
  0.035395972430706024,
  0.20192381739616394,
  0.06605634093284607,
  -0.08378880470991135,
  0.22563409805297852,
  -0.03353658318519592,
  -0.009824170731008053,
  0.03149435669183731,
  0.053288161754608154,
  -0.13306517899036407,
  0.009709521196782589,
  -0.14351588487625122,
  -0.07711762934923172,
  -0.006894826889038086,
  -0.10198317468166351,
  -0.0057301707565784454,
  0.06865299493074417,
  -0.17035546898841858,
  0.1783592253923416,
  0.0338282585144043,
  -0.008667205460369587,
  -0.054691165685653687,
  0.04564194008708,
  -0.16061435639858246,
  -0.028685683384537697,
  0.1652255356311798,
  -0.2981248199939728,
  0.16866472363471985,
  0.09358249604701996,
  0.1602584421634674,
  0.1920686960220337,
  0.09039424359798431,
  0.0016910973936319351,
  0.008445389568805695,
  -0.0737486332654953,
  -0.07163585722446442,
  -0.08086562156677246,
  0.009611545130610466,
  0.02540716528892517,
  0.0788404643535614,
  -0.00012753636110574007,
  0 ],
[ -0.17139741778373718,
  0.16418175399303436,
  -0.005330130457878113,
  -0.03825699910521507,
  -0.02452382631599903,
  -0.04349328204989433,
  -0.08185134083032608,
  -0.09630785882472992,
  0.16133058071136475,
  -0.013942019082605839,
  0.2309294492006302,
  -0.017165523022413254,
  -0.2400040328502655,
  -0.029994746670126915,
  -0.06522569060325623,
  0.021044733002781868,
  -0.18622596561908722,
  -0.14369285106658936,
  0.052289437502622604,
  -0.061528921127319336,
  0.08725947886705399,
  -0.005723526235669851,
  -0.015962019562721252,
  0.07007985562086105,
  -0.1806076318025589,
  -0.32842010259628296,
  -0.06767609715461731,
  -0.10046720504760742,
  -0.004748167470097542,
  -0.09453191608190536,
  0.10095695406198502,
  0.07041749358177185,
  -0.14785274863243103,
  0.0186753049492836,
  0.017370300367474556,
  0.07097531110048294,
  -0.013168343342840672,
  0.026463966816663742,
  0.23086217045783997,
  0.02822328917682171,
  -0.10937773436307907,
  -0.02580360509455204,
  -0.0021836641244590282,
  0.39112719893455505,
  0.11134330928325653,
  -0.008174097165465355,
  0.02148500271141529,
  -0.05345293879508972,
  0.09294544160366058,
  -0.2036760002374649,
  0.08461028337478638,
  0.24298597872257233,
  0.11058805882930756,
  0.03614933043718338,
  0.06409677863121033,
  -0.11057189106941223,
  -0.019443627446889877,
  0.1182023286819458,
  -0.2270497828722,
  0.153053879737854,
  0.08072109520435333,
  -0.06476528942584991,
  -0.02822485938668251,
  -0.08688262104988098,
  0.1630977988243103,
  0.07538462430238724,
  -0.14325439929962158,
  -0.14786839485168457,
  0.11546147614717484,
  -0.11882902681827545,
  -0.06211446598172188,
  0.12661632895469666,
  -0.08472367376089096,
  -0.27786728739738464,
  -0.2141665667295456,
  0.1064981147646904,
  0.3635678291320801,
  0.18429329991340637,
  -0.1546906679868698,
  0.05330957844853401,
  -0.09382502734661102,
  -0.10929262638092041,
  0.03754398971796036,
  0.015401165932416916,
  -0.0854448601603508,
  0.008468469604849815,
  -0.13221420347690582,
  0.04017229378223419,
  0.19107121229171753,
  0.059214577078819275,
  -0.08825675398111343,
  0.22381344437599182,
  -0.029926497489213943,
  -0.00679995771497488,
  0.021784987300634384,
  0.05758515000343323,
  -0.1512613594532013,
  0.00587961170822382,
  -0.1480630785226822,
  -0.08159802109003067,
  -0.007582138758152723,
  -0.102321557700634,
  -0.014988545328378677,
  0.07633694261312485,
  -0.16332188248634338,
  0.16809284687042236,
  0.03887529671192169,
  -0.01508345827460289,
  -0.06974782794713974,
  0.052530840039253235,
  -0.1570339798927307,
  -0.03654302656650543,
  0.16801154613494873,
  -0.2915681004524231,
  0.1907963901758194,
  0.10055829584598541,
  0.15815483033657074,
  0.18217606842517853,
  0.08912051469087601,
  -0.006125446408987045,
  0.020653605461120605,
  -0.061199821531772614,
  -0.07573855668306351,
  -0.07511238753795624,
  0.003286813385784626,
  0.03008178621530533,
  0.06727494299411774,
  0.006314115133136511,
  0 ],
[ -0.16052058339118958,
  0.15287595987319946,
  0.000920955091714859,
  -0.03970065340399742,
  -0.0220053531229496,
  -0.04566332697868347,
  -0.07997789233922958,
  -0.09680525213479996,
  0.13594353199005127,
  -0.02062937803566456,
  0.23099492490291595,
  -0.023192837834358215,
  -0.2290302813053131,
  -0.039720527827739716,
  -0.06371916085481644,
  0.023183181881904602,
  -0.1622684895992279,
  -0.14250898361206055,
  0.0520310178399086,
  -0.061227478086948395,
  0.09105217456817627,
  -0.00031132204458117485,
  -0.01941034197807312,
  0.09513138234615326,
  -0.18832740187644958,
  -0.3086247742176056,
  -0.05896816402673721,
  -0.09189674258232117,
  -0.01757653057575226,
  -0.1001187264919281,
  0.10790697485208511,
  0.08497641235589981,
  -0.1432945728302002,
  0.022546028718352318,
  0.012069405987858772,
  0.05996794253587723,
  -0.0045813885517418385,
  0.023195428773760796,
  0.23398396372795105,
  0.03527817502617836,
  -0.11518824845552444,
  -0.02135513350367546,
  0.008124325424432755,
  0.3903888761997223,
  0.09613417834043503,
  -0.011932188645005226,
  0.02097484841942787,
  -0.05547085776925087,
  0.10030495375394821,
  -0.20664720237255096,
  0.0665932148694992,
  0.23599570989608765,
  0.0997372418642044,
  0.025302737951278687,
  0.06246355175971985,
  -0.10448332130908966,
  -0.010431163012981415,
  0.11867358535528183,
  -0.2224036008119583,
  0.15875467658042908,
  0.06007403880357742,
  -0.0650869607925415,
  -0.02782610058784485,
  -0.103447325527668,
  0.14353235065937042,
  0.0691007450222969,
  -0.1303534060716629,
  -0.138441264629364,
  0.11210966110229492,
  -0.11852742731571198,
  -0.07929839938879013,
  0.13586902618408203,
  -0.0797855406999588,
  -0.2727068364620209,
  -0.22142213582992554,
  0.09718714654445648,
  0.3448779582977295,
  0.1986914575099945,
  -0.15745998919010162,
  0.06144094467163086,
  -0.07588935643434525,
  -0.09601974487304688,
  0.04479653015732765,
  0.012992101721465588,
  -0.08984120190143585,
  0.008778585121035576,
  -0.11738938838243484,
  0.04024794325232506,
  0.18813692033290863,
  0.07310380786657333,
  -0.08093323558568954,
  0.23000480234622955,
  -0.021720480173826218,
  -0.0031812237575650215,
  0.026767510920763016,
  0.04885176569223404,
  -0.14924193918704987,
  0.011074052192270756,
  -0.15008381009101868,
  -0.07324497401714325,
  -0.0014727612724527717,
  -0.09829999506473541,
  0.0066460855305194855,
  0.08034542202949524,
  -0.1778167337179184,
  0.16591356694698334,
  0.033763520419597626,
  -0.017972061410546303,
  -0.053932830691337585,
  0.07925084233283997,
  -0.16149267554283142,
  -0.0331486314535141,
  0.15797847509384155,
  -0.27789920568466187,
  0.1741803139448166,
  0.10175349563360214,
  0.15830294787883759,
  0.1656186729669571,
  0.10569698363542557,
  -0.0016709566116333008,
  0.009640288539230824,
  -0.06197211146354675,
  -0.07315479218959808,
  -0.07384735345840454,
  0.025905635207891464,
  0.014606451615691185,
  0.07000449299812317,
  -0.0015584701905027032,
  0 ],
[ -0.16903038322925568,
  0.13572101294994354,
  -0.0029139546677470207,
  -0.024419134482741356,
  -0.03476434946060181,
  -0.06729979813098907,
  -0.11590930819511414,
  -0.08571895956993103,
  0.1397104263305664,
  -0.022242341190576553,
  0.17119793593883514,
  -0.012172042392194271,
  -0.2197238653898239,
  -0.01169898733496666,
  -0.05905476212501526,
  0.01658463478088379,
  -0.17014114558696747,
  -0.13723143935203552,
  0.019738154485821724,
  -0.09902666509151459,
  0.08334669470787048,
  0.07323281466960907,
  -0.010632463730871677,
  0.09532545506954193,
  -0.1302422136068344,
  -0.3429376780986786,
  -0.09521770477294922,
  -0.09574510157108307,
  0.010435650125145912,
  -0.0848667174577713,
  0.08416493982076645,
  0.06610751152038574,
  -0.12938567996025085,
  -0.0023328084498643875,
  0.023513412103056908,
  0.07912753522396088,
  -0.0007846863009035587,
  0.01230428833514452,
  0.23360180854797363,
  0.02970915660262108,
  -0.06533180177211761,
  -0.0030089961364865303,
  -0.011651262640953064,
  0.3995290994644165,
  0.14615990221500397,
  0.04459870234131813,
  0.03561386466026306,
  -0.027180317789316177,
  0.1303441971540451,
  -0.22567281126976013,
  0.10654787719249725,
  0.2439921498298645,
  0.09196112304925919,
  0.01208433322608471,
  0.12170767039060593,
  -0.12962603569030762,
  -0.044465579092502594,
  0.08326932042837143,
  -0.17504553496837616,
  0.13065266609191895,
  0.04411797225475311,
  0.0007209824398159981,
  -0.0428193174302578,
  -0.10936944931745529,
  0.12000538408756256,
  0.062482673674821854,
  -0.11763335764408112,
  -0.1369030624628067,
  0.11950403451919556,
  -0.1559537798166275,
  -0.08335867524147034,
  0.1040799617767334,
  -0.10409870743751526,
  -0.22994714975357056,
  -0.22465771436691284,
  0.08297111093997955,
  0.37367236614227295,
  0.1555568277835846,
  -0.1595323532819748,
  0.06753738224506378,
  -0.02303115837275982,
  -0.08918555825948715,
  0.05314530059695244,
  -0.03222337365150452,
  -0.11412826925516129,
  0.006225552409887314,
  -0.1411464363336563,
  0.06144600734114647,
  0.18987858295440674,
  0.07705288380384445,
  -0.10549139976501465,
  0.19652675092220306,
  -0.013928585685789585,
  0.01268427912145853,
  0.07063552737236023,
  0.09306269884109497,
  -0.1095929816365242,
  -0.012415150180459023,
  -0.16346827149391174,
  -0.03026975691318512,
  0.06905482709407806,
  -0.0790669322013855,
  -0.04598480463027954,
  0.06729992479085922,
  -0.14800497889518738,
  0.19399818778038025,
  0.01207359042018652,
  -0.005485731177031994,
  -0.10469641536474228,
  0.04712967574596405,
  -0.22993263602256775,
  0.03119376301765442,
  0.21033252775669098,
  -0.2426021695137024,
  0.16192102432250977,
  0.09709997475147247,
  0.07090053707361221,
  0.17999745905399323,
  0.06524114310741425,
  0.0006222985684871674,
  -0.013086008839309216,
  -0.051154181361198425,
  -0.11421147733926773,
  -0.1480822116136551,
  0.011724338866770267,
  0.04760647565126419,
  0.04826947674155235,
  0.03298989683389664,
  1 ],
[ -0.17481793463230133,
  0.1496385633945465,
  -0.015075333416461945,
  -0.007144240662455559,
  -0.03522232174873352,
  -0.05253695696592331,
  -0.1132827177643776,
  -0.0835316851735115,
  0.1361808329820633,
  -0.022421911358833313,
  0.1813545823097229,
  -0.017910314723849297,
  -0.2236870974302292,
  -0.02277470752596855,
  -0.06388093531131744,
  0.04006027430295944,
  -0.16488108038902283,
  -0.1533263772726059,
  0.02135300450026989,
  -0.10108683258295059,
  0.08239588141441345,
  0.06386952102184296,
  -0.0038459186907857656,
  0.09046858549118042,
  -0.1607031524181366,
  -0.3424597382545471,
  -0.08730147778987885,
  -0.11845887452363968,
  -0.0010409383103251457,
  -0.09831398725509644,
  0.06815508008003235,
  0.0660647377371788,
  -0.1352258324623108,
  -0.008646944537758827,
  0.02681761048734188,
  0.08728361129760742,
  0.017467647790908813,
  0.02557291090488434,
  0.22592313587665558,
  0.03799775615334511,
  -0.06808532029390335,
  0.0140165314078331,
  -0.005503586493432522,
  0.40540221333503723,
  0.130202978849411,
  0.03715522214770317,
  0.042792558670043945,
  -0.03400527685880661,
  0.11206167936325073,
  -0.21070851385593414,
  0.1003776341676712,
  0.23712892830371857,
  0.0784820020198822,
  0.030044762417674065,
  0.10623214393854141,
  -0.11480709165334702,
  -0.03819938004016876,
  0.07620791345834732,
  -0.177766352891922,
  0.1224290058016777,
  0.056622155010700226,
  0.02246687188744545,
  -0.04335763305425644,
  -0.0993955060839653,
  0.11871209740638733,
  0.0560789555311203,
  -0.11340934783220291,
  -0.12931391596794128,
  0.10257979482412338,
  -0.15122321248054504,
  -0.07450078427791595,
  0.10421814769506454,
  -0.1040351390838623,
  -0.23229609429836273,
  -0.22258900105953217,
  0.09132354706525803,
  0.3725988268852234,
  0.16124919056892395,
  -0.15152256190776825,
  0.06889034807682037,
  -0.02342529594898224,
  -0.09023670852184296,
  0.050223562866449356,
  -0.03749369829893112,
  -0.10390693694353104,
  0.023219279944896698,
  -0.1317959725856781,
  0.07889130711555481,
  0.18543490767478943,
  0.07684694230556488,
  -0.08744791150093079,
  0.19855016469955444,
  -0.014488562941551208,
  0.0054031852632761,
  0.07637298852205276,
  0.11580613255500793,
  -0.11423791944980621,
  -0.015838999301195145,
  -0.14923430979251862,
  -0.03420271351933479,
  0.060759954154491425,
  -0.08450155705213547,
  -0.03981950506567955,
  0.05501830577850342,
  -0.14745387434959412,
  0.1763361245393753,
  0.0044316137209534645,
  -0.005732751451432705,
  -0.10968802869319916,
  0.07055257260799408,
  -0.21175363659858704,
  0.02035434916615486,
  0.19820821285247803,
  -0.24200724065303802,
  0.1545376032590866,
  0.11115700006484985,
  0.05059549957513809,
  0.1685696542263031,
  0.06921735405921936,
  0.006618080660700798,
  -0.02567272260785103,
  -0.047728266566991806,
  -0.10615536570549011,
  -0.14859013259410858,
  0.012463260442018509,
  0.05129188299179077,
  0.04821519926190376,
  0.0259077288210392,
  1 ],
[ -0.17826911807060242,
  0.13712704181671143,
  -0.02724616229534149,
  -0.0031820200383663177,
  -0.04055416211485863,
  -0.04722712188959122,
  -0.11408860981464386,
  -0.06938545405864716,
  0.13033714890480042,
  -0.027219975367188454,
  0.18105025589466095,
  -0.0216017235070467,
  -0.2221134901046753,
  -0.03146206587553024,
  -0.059675879776477814,
  0.04117298871278763,
  -0.16614842414855957,
  -0.14764532446861267,
  0.04046565666794777,
  -0.0876157134771347,
  0.1136956587433815,
  0.052042655646800995,
  -0.0036395892966538668,
  0.10336341708898544,
  -0.15530405938625336,
  -0.33935263752937317,
  -0.0949583649635315,
  -0.09799259155988693,
  0.026886869221925735,
  -0.07336096465587616,
  0.05129921808838844,
  0.060340479016304016,
  -0.13446055352687836,
  0.002043597400188446,
  0.018291691318154335,
  0.07792189717292786,
  0.02325587347149849,
  0.018922273069620132,
  0.22801066935062408,
  0.04732406884431839,
  -0.07868410646915436,
  0.027821853756904602,
  -0.017040962353348732,
  0.39716798067092896,
  0.13400444388389587,
  0.03810986876487732,
  0.05481312796473503,
  -0.02129511721432209,
  0.12310856580734253,
  -0.23184965550899506,
  0.09877841174602509,
  0.24858567118644714,
  0.08777713030576706,
  0.015723595395684242,
  0.09966163337230682,
  -0.1280290186405182,
  -0.04774735867977142,
  0.10299894213676453,
  -0.17885714769363403,
  0.14677362143993378,
  0.03152799978852272,
  0.020356468856334686,
  -0.024332720786333084,
  -0.10300904512405396,
  0.11716098338365555,
  0.07068665325641632,
  -0.1169038936495781,
  -0.1541454941034317,
  0.11086105555295944,
  -0.15661905705928802,
  -0.07145386934280396,
  0.12114999443292618,
  -0.11154812574386597,
  -0.23950380086898804,
  -0.2319190800189972,
  0.10120809823274612,
  0.37944018840789795,
  0.17166930437088013,
  -0.15259723365306854,
  0.08127455413341522,
  -0.02062600664794445,
  -0.08168267458677292,
  0.057125650346279144,
  -0.016893045976758003,
  -0.09687157720327377,
  0.011617367155849934,
  -0.15538747608661652,
  0.04911167547106743,
  0.19000566005706787,
  0.07187343388795853,
  -0.09394731372594833,
  0.21736156940460205,
  0.0006327703595161438,
  0.02104911580681801,
  0.07178708165884018,
  0.11877049505710602,
  -0.11966800689697266,
  -0.029802346602082253,
  -0.13876953721046448,
  -0.0443761944770813,
  0.04199383407831192,
  -0.09336714446544647,
  -0.04284227639436722,
  0.06039554253220558,
  -0.14262282848358154,
  0.17885884642601013,
  -0.01524814497679472,
  0.004881740547716618,
  -0.12452160567045212,
  0.07039875537157059,
  -0.1996094435453415,
  0.03310893476009369,
  0.1726103127002716,
  -0.24667416512966156,
  0.1492084115743637,
  0.11194279789924622,
  0.06771482527256012,
  0.17565350234508514,
  0.07595070451498032,
  0.009048066101968288,
  -0.016751157119870186,
  -0.04503171890974045,
  -0.0947948545217514,
  -0.147939532995224,
  0.002817985601723194,
  0.038967739790678024,
  0.03996100649237633,
  0.029715480282902718,
  1 ] ]

const testEmbedding = [ -0.12392137199640274,
  0.10858161747455597,
  -0.010810323990881443,
  -0.08238714933395386,
  -0.02436506375670433,
  -0.06392952054738998,
  -0.059869833290576935,
  -0.11819372326135635,
  0.15747667849063873,
  -0.04154639318585396,
  0.262457013130188,
  -0.03673039376735687,
  -0.23353399336338043,
  -0.03605730086565018,
  -0.0898868665099144,
  0.03661200404167175,
  -0.20297077298164368,
  -0.14198274910449982,
  0.02493126317858696,
  -0.07498283684253693,
  0.10631556063890457,
  -0.008591385558247566,
  -0.002523483242839575,
  0.11032450199127197,
  -0.1618250608444214,
  -0.3218114674091339,
  -0.0892954021692276,
  -0.08690045028924942,
  0.022108905017375946,
  -0.09561339765787125,
  0.07961342483758926,
  0.06496941298246384,
  -0.16854502260684967,
  -0.007907567545771599,
  -0.00015064701437950134,
  0.07344627380371094,
  0.00535115459933877,
  -0.02182052657008171,
  0.21362341940402985,
  0.018943268805742264,
  -0.12092721462249756,
  0.008090944029390812,
  -0.00502459891140461,
  0.35311028361320496,
  0.11784940212965012,
  0.006852429360151291,
  0.04090104624629021,
  -0.07109521329402924,
  0.06265964359045029,
  -0.19706390798091888,
  0.0730615183711052,
  0.22918418049812317,
  0.09619627147912979,
  0.013880275189876556,
  0.023791875690221786,
  -0.112578846514225,
  -0.02009051851928234,
  0.14732849597930908,
  -0.1963246613740921,
  0.11762512475252151,
  0.08887003362178802,
  -0.06060341000556946,
  0.019093751907348633,
  -0.07812372595071793,
  0.13626623153686523,
  0.054233044385910034,
  -0.1495487540960312,
  -0.11758945137262344,
  0.10143575817346573,
  -0.13746120035648346,
  -0.07107221335172653,
  0.08313603699207306,
  -0.10183176398277283,
  -0.25349345803260803,
  -0.25004467368125916,
  0.09984191507101059,
  0.42448729276657104,
  0.17919126152992249,
  -0.13227052986621857,
  0.06049008667469025,
  -0.11211847513914108,
  -0.06630644202232361,
  0.06642823666334152,
  0.011571072041988373,
  -0.09307193011045456,
  0.0014964817091822624,
  -0.15720197558403015,
  0.06530880182981491,
  0.17726652324199677,
  0.0620233453810215,
  -0.08318070322275162,
  0.20443058013916016,
  -0.03596031665802002,
  0.016875529661774635,
  0.031575947999954224,
  0.08910410851240158,
  -0.1518571674823761,
  0.03860298544168472,
  -0.12100346386432648,
  -0.014514992013573647,
  -0.028949296101927757,
  -0.0720764771103859,
  -0.0071795228868722916,
  0.09058329463005066,
  -0.14618068933486938,
  0.14969614148139954,
  0.02251703105866909,
  -0.04327869042754173,
  -0.06226824223995209,
  0.06887811422348022,
  -0.14170481264591217,
  -0.06001028046011925,
  0.14186514914035797,
  -0.27614283561706543,
  0.14100201427936554,
  0.1522182673215866,
  0.15699689090251923,
  0.19575420022010803,
  0.10434040427207947,
  0.014854179695248604,
  0.009579971432685852,
  -0.06472702324390411,
  -0.11444613337516785,
  -0.06228937581181526,
  0.010687767527997494,
  0.03489101678133011,
  0.10200808197259903,
  0.0057195033878088]

const labels=["A","B"];

/*
 * split in training and testing data
 * Split in X and Y for training and testing, with:
 * X array of length-127 array of embeddings
 * Y array of number, representing the label, with the same length as X
 */
function prepareData(dataEmbedding,testSplit) {
  return tf.tidy(() => {
    const dataByClass = [];
    const targetsByClass = [];
    for (let i=0 ; i < labels.length ; i=i+1) {
      dataByClass.push([]);
      targetsByClass.push([]);
    }
    for (let k=0; k < dataEmbedding.length ; k=k+1) {
      const element = dataEmbedding[k];
      const target = element[element.length -1];
      const data = element.slice(0, element.length-1);
      targetsByClass[target].push(target);
      dataByClass[target].push(data);
    }
    console.log(dataByClass);
    console.log(targetsByClass);
    const xTrains = [];
    const yTrains = [];
    const xTests = [];
    const yTests = [];
    for (let i=0 ; i < labels.length ; i=i+1) {
      const [xTrain, yTrain, xTest, yTest] = convertToTensor(dataByClass[i], targetsByClass[i], testSplit);
      xTrains.push(xTrain);
      yTrains.push(yTrain);
      xTests.push(xTest);
      yTests.push(yTest);
    }

    const concatAxis = 0;
    const test1 = xTrains;
    const test2 = tf.concat(xTrains,concatAxis);
    console.log(test1);
    console.log(test2);
    return [
      tf.concat(xTrains,concatAxis), tf.concat(yTrains,concatAxis),
      tf.concat(xTests,concatAxis), tf.concat(yTests,concatAxis)
    ];
  });
}


function convertToTensor(data, targets, testSplit) {
  const numExamples= data.length;
  if (numExamples!== targets.length) {
    throw new Error('data and targets have different number of examples');
  }
  
  const numTestExamples = Math.round(numExamples * testSplit);
  const numTrainExamples = numExamples-numTestExamples;

  const xDims = data[0].length;
  // create a 2D tf.Tensor to hold the embeddings data
  const xs = tf.tensor2d(data, [numExamples, xDims]);

  // Create 1D ts.Tensor to hold the labels and convert to one hot encoding
  const ys = tf.oneHot(tf.tensor1d(targets).toInt(), labels.length);

  // Split into training and testing data
  const xTrain = xs.slice([0,0],[numTrainExamples, xDims]);
  const xTest = xs.slice([numTrainExamples,0],[numTestExamples, xDims]);
  const yTrain = ys.slice([0,0],[numTrainExamples, labels.length]);
  const yTest = ys.slice([numTrainExamples,0],[numTestExamples, labels.length]);
  return [xTrain, yTrain, xTest, yTest];
}


// Train the model
async function trainModel(xTrain, yTrain, xTest, yTest){
  const model = tf.sequential();
  const learningRate = 0.01;
  const numberOfEpochs = 40;
  const optimizer = tf.train.adam(learningRate);

  model.add(tf.layers.dense(
    { units:10, activation: 'sigmoid', inputShape: [xTrain.shape[1]]}));
  
  model.add(tf.layers.dense(
    { units:labels.length, activation: 'softmax'}));
    
  model.compile(
    {optimizer: optimizer, loss: 'categoricalCrossentropy', metrics: ['accuracy']});
  console.log(yTrain);
  const history = await model.fit(xTrain, yTrain,
    {epochs: numberOfEpochs, validationData: [xTest, yTest],
      callbacks: {
          onEpochEnd: async (epoch, logs) => {
            console.log("Epoch: " + epoch + " logs: " + logs.loss);
            await tf.nextFrame();
          }
      }
    });
  return model
}

async function doEmbedding(detectionThreshold){
  const [xTrain, yTrain, xTest, yTest] = prepareData(dataEmbedding,0.2);

  model = await trainModel(xTrain, yTrain, xTest, yTest);

  const input = tf.tensor2d(testEmbedding, [1, 128]);
  const prediction = model.predict(input);
  alert(prediction);
  
  // detect with a specific threshold
  if (prediction.max().dataSync()[0] > detectionThreshold){
    const predictionWithArgMax = prediction.argMax(-1).dataSync();
    alert(predictionWithArgMax);
  }
  else {
    alert('unknown')
  }

  const xData = xTest.dataSync();
  const yTrue = yTest.argMax(-1).dataSync();

  const predictions = await model.predict(xTest);
  const yPred = predictions.argMax(-1).dataSync();

  var correct = 0;
  var wrong = 0;

  for(let i = 0; i<yTrue.length; i=i+1) {
    if (yTrue[i] == yPred[i]) {
      correct=correct+1;
    }
    else{
      wrong=wrong+1;
    }
  }
  alert("Prediction error rate: " + (wrong/ yTrue.length));
}


